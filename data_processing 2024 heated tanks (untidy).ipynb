{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Lab data \n",
    "Does some cleaning, similar timestamps are grouped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def group_timestamps(timestamps, avg_window_hours=24):\n",
    "    # a list of timestamp ranges that are close to each other\n",
    "    timestamp_groups = []\n",
    "\n",
    "    # find timestamps that are within 24 hours of any other timestamp\n",
    "    for i in timestamps:\n",
    "        similar_timestamps = []\n",
    "        for t in timestamps:\n",
    "            if abs(t-i) < pd.Timedelta(hours=avg_window_hours):\n",
    "                similar_timestamps.append(t)\n",
    "\n",
    "        # remove the timestamps that are similar to the current timestamp, as they are already in the list\n",
    "        for s in similar_timestamps:\n",
    "            timestamps = timestamps[timestamps != s]\n",
    "\n",
    "        if len(similar_timestamps) > 0:\n",
    "            timestamp_groups.append(similar_timestamps)\n",
    "\n",
    "    return timestamp_groups\n",
    "\n",
    "with open('Lab Results Compiled.xlsx', 'rb') as f:\n",
    "    input_df = pd.read_excel(f, sheet_name='Analytics Model - LIMS')\n",
    "\n",
    "dashboard_data = []\n",
    "output_df = pd.DataFrame()\n",
    "\n",
    "# remove pesky trailing spaces\n",
    "input_df['Tank'] = input_df['Tank'].str.rstrip()\n",
    "\n",
    "tanks = input_df['Tank'].unique()\n",
    "\n",
    "for t in tanks:\n",
    "    # extract data relevant to current tank\n",
    "    gc_data = input_df[input_df['Tank'] == t]\n",
    "\n",
    "    timestamps = gc_data[\"SampleResults[Sampled Timestamp]\"]\n",
    "\n",
    "    # figure out if any timestamps are close enough to be averaged\n",
    "    timestamp_groups = group_timestamps(timestamps, avg_window_hours=24)\n",
    "\n",
    "    for g in timestamp_groups:\n",
    "        # extract the data for the current timestamp group\n",
    "        data_to_avg = gc_data[gc_data['SampleResults[Sampled Timestamp]'].isin(g)]\n",
    "\n",
    "        determinands = data_to_avg['Determinand[Determinand Name]'].unique()\n",
    "\n",
    "        for d in determinands:\n",
    "            # extract the data for the current determinand\n",
    "            determinand_df = data_to_avg[data_to_avg['Determinand[Determinand Name]'] == d]\n",
    "            determinand_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            result = determinand_df['SampleResults[Sample Result]']\n",
    "            unit = determinand_df['Determinand[Unit of Measure]'][0]\n",
    "            sample_nums = determinand_df['SampleResults[SampleNumber]'].unique()\n",
    "\n",
    "            # remove any < or > from the result\n",
    "            result = result.astype(str).str.replace(\"<\", \"\")\n",
    "            result = result.astype(str).str.replace(\">\", \"\")\n",
    "            result = pd.to_numeric(result, errors='raise')\n",
    "\n",
    "            std_dev = result.std()\n",
    "            std_dev = round(std_dev, 2)\n",
    "            result = result.mean()\n",
    "            result = round(result, 2)\n",
    "\n",
    "            time = pd.Timestamp(g[0])\n",
    "\n",
    "            # Some formatting for output\n",
    "\n",
    "            # remove spaces from determinand\n",
    "            determinand = d.replace(\" \", \"-\")\n",
    "\n",
    "            # add ST to tank name unless it is INLET\n",
    "            tank = t\n",
    "            # if tank != \"INLET\":\n",
    "            #     tank = f\"ST{tank}\"\n",
    "\n",
    "            if len(tank) == 5:\n",
    "                tank = tank.replace(\" \", \".\")\n",
    "            if len(tank) == 4:\n",
    "                tank = tank.replace(\" \", \"C.\")\n",
    "\n",
    "            dashboard_sample = {\n",
    "                \"key\"    : f\"{tank}.{determinand}\",\n",
    "                \"value\"  : result,\n",
    "                \"epoch\"  : time.timestamp()\n",
    "            }\n",
    "\n",
    "            df_sample = pd.DataFrame({\n",
    "                \"tank\"        : tank,\n",
    "                \"determinand\" : d,\n",
    "                \"value\"       : result,\n",
    "                \"std_dev\"     : std_dev,\n",
    "                \"unit\"        : unit,\n",
    "                \"timestamp\"   : time,\n",
    "                \"sample_nums\" : str(sample_nums)\n",
    "            }, index=[0])\n",
    "\n",
    "            dashboard_data.append(dashboard_sample)\n",
    "            output_df = pd.concat([output_df, df_sample], axis=0, ignore_index=True)\n",
    "print(dashboard_data)\n",
    "output_df\n",
    "output_df.to_csv(\"lab_data.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just a quick check to make sure the tank names are correct\n",
    "input_df['Tank'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Export the lab data to excel (optional)\n",
    "\n",
    "with pd.ExcelWriter(\"output.xlsx\") as writer:\n",
    "\n",
    "    output_df.to_excel(writer, sheet_name=\"Averaged Data\")\n",
    "    input_df.to_excel(writer, sheet_name=\"Original Data\")\n",
    "    \n",
    "\n",
    "    tanks = ['CON', 'INS', '20C', '30C', 'INLET']\n",
    "    for t in tanks:\n",
    "\n",
    "        # select from output_df where tank name starts with e.g. \"STINS\"\n",
    "        tab_df = output_df[output_df['tank'].str.startswith(t)]\n",
    "\n",
    "        # arrange so the individual tanks are shown are side by side\n",
    "        tab_df = tab_df.pivot_table(index=['determinand', 'unit' ], columns=['tank', 'timestamp'], values='value')\n",
    "        tab_df.to_excel(writer, sheet_name=t)\n",
    "\n",
    "\n",
    "# # resize the columns in the excel file to fit the data, while handling merged cells\n",
    "import openpyxl\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.styles import Alignment\n",
    "\n",
    "wb = openpyxl.load_workbook(\"output.xlsx\")\n",
    "\n",
    "for ws in wb.worksheets:\n",
    "    for col in ws.columns:\n",
    "        max_length = 0\n",
    "        try:\n",
    "            column = col[0].column_letter\n",
    "        except:\n",
    "            column = col[1].column_letter\n",
    "\n",
    "\n",
    "\n",
    "        for cell in col:\n",
    "            cell.alignment = Alignment(wrap_text=True)\n",
    "            if len(str(cell.value)) > max_length:\n",
    "                max_length = len(str(cell.value))\n",
    "\n",
    "        adjusted_width = (max_length + 2) * 1.2\n",
    "        ws.column_dimensions[column].width = adjusted_width\n",
    "\n",
    "# Tweak the format of the tank specific sheets\n",
    "tanks = ['CON', 'INS', '20C', '30C', 'INLET']\n",
    "\n",
    "for t in tanks:\n",
    "    ws = wb[t]\n",
    "\n",
    "    # set the format of row 2, columns c onwards to be a date\n",
    "    for col in ws.columns:\n",
    "        letter = col[1].column_letter\n",
    "        if letter in [\"A\", \"B\"]:\n",
    "            continue\n",
    "        cell = col[1]\n",
    "        cell.number_format = \"mmm-dd\"\n",
    "        ws.column_dimensions[letter].width = 9\n",
    "\n",
    "\n",
    "wb.save(\"output.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This was helpful for generating the label and unit mappings below.\n",
    "# No need to run every time\n",
    "\n",
    "# create a new df from lab_df selecting columns \"unit\" \"and determinand\"\n",
    "unit_mapping_df = lab_df[[\"unit\", \"determinand\"]].drop_duplicates()\n",
    "\n",
    "# make a new column that is the concatenation of the unit and determinand\n",
    "unit_mapping_df[\"label\"] = unit_mapping_df[\"determinand\"] + \" (\" + unit_mapping_df[\"unit\"] +\")\"\n",
    "unit_mapping_dict = unit_mapping_df.set_index(\"determinand\").to_dict()[\"label\"]\n",
    "unit_mapping_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in the sensor Data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Split into 2 to stay below github 100MB limit\n",
    "sensor_df = pd.read_csv(\"2024 data initial_state_backup.csv\", names=[\"timestamp\", \"key\", \"value\"], low_memory=False)\n",
    "# sensor_df = pd.read_csv(\"initial_state_backup.csv\", names=[\"timestamp\", \"key\", \"value\"], low_memory=False)\n",
    "# sensor_df2 = pd.read_csv(\"initial_state_backup_august_onward.csv\", names=[\"timestamp\", \"key\", \"value\"], low_memory=False)\n",
    "# sensor_df = pd.read_csv(\"initial_state_backup_2023-11-29.csv\", names=[\"timestamp\", \"key\", \"value\"], low_memory=False)\n",
    "\n",
    "\n",
    "unit_mapping = {\n",
    "    \"ts\" : \"C\",\n",
    "    \"tl\" : \"C\",\n",
    "    \"ph\" : \"pH\",\n",
    "    \"pr\" : \"mBar\",\n",
    "    \"gc\" : \"%CH4\",\n",
    "}\n",
    "\n",
    "labels_mapping = {\n",
    "    \"ts\"                            : \"Top Temp (C)\",\n",
    "    \"tl\"                            : \"Bottom Temp (C)\",\n",
    "    \"ph\"                            : \"pH\",\n",
    "    \"pr\"                            : \"Pressure (mBar)\",\n",
    "    \"gc\"                            : \"CH4 Concentration (%)\",\n",
    "    'Total Nitrogen (as N)'         : 'Total Nitrogen (as N) (mg/l as N)',\n",
    "    'Ammonia'                       : 'Ammonia (mg/l as N)',\n",
    "    'Nitrate'                       : 'Nitrate (mg/l as N)',\n",
    "    'Nitrite'                       : 'Nitrite (mg/l as N)',\n",
    "    'Total oxidised nitrogen'       : 'Total oxidised nitrogen (mg/l as N)',\n",
    "    'Phosphorus'                    : 'Phosphorus (mgP/l)',\n",
    "    'Sulphate'                      : 'Sulphate (mgSO₄/l)',\n",
    "    'Suspended solids'              : 'Suspended solids (mg/l)',\n",
    "    'Total Chemical Oxygen Demand'  : 'Total Chemical Oxygen Demand (mgO₂/l)',\n",
    "    'Soluble Chemical Oxygen Demand': 'Soluble Chemical Oxygen Demand (mgO₂/l)',\n",
    "    'Biochemical oxygen demand'     : 'Biochemical oxygen demand (mgO₂/l)',\n",
    "    'Total organic carbon'          : 'Total organic carbon (mgC/l)',\n",
    "    'Alkalinity'                    : 'Alkalinity (mgCaCO₃/l)',\n",
    "    'Conductivity'                  : 'Conductivity (mS/cm)',\n",
    "    'Manganese'                     : 'Manganese (mgMn/l)',\n",
    "}\n",
    "\n",
    "def clean_sensor_df(sensor_df):\n",
    "\n",
    "    #remove keys we don't need\n",
    "    sensor_df = sensor_df[~sensor_df[\"key\"].str.contains(\".tc\")]\n",
    "    sensor_df = sensor_df[~sensor_df[\"key\"].str.contains(\"TEST\")]\n",
    "    sensor_df = sensor_df[~sensor_df[\"key\"].str.contains(\"debug\")]\n",
    "    sensor_df = sensor_df[~sensor_df[\"key\"].str.contains(\"feedcontrol\")]\n",
    "    sensor_df = sensor_df[~sensor_df[\"key\"].str.contains(\"feedcontrol_new\")]\n",
    "\n",
    "    # Reformat the key (Move the final number from the key to the end of the tank name, and drop \"ST\")\n",
    "    sensor_df[\"key\"] = sensor_df[\"key\"].str[2:5]+\".\"+sensor_df[\"key\"].str[-1]+sensor_df[\"key\"].str[5:-1]\n",
    "\n",
    "    # rename key CON.4.ts to AMB\n",
    "    sensor_df[\"key\"] = sensor_df[\"key\"].str.replace(\"CON.4.ts\",\"AMB.ts\", regex=False)\n",
    "\n",
    "    sensor_df[\"key\"] = sensor_df[\"key\"].str.replace(\"CON.4.gc\",\"AMB.gc\", regex=False)\n",
    "    sensor_df[\"key\"] = sensor_df[\"key\"].str.replace(\"CON.4.pr\",\"AMB.pr\", regex=False)\n",
    "\n",
    "    sensor_df = sensor_df[~sensor_df[\"key\"].str.contains(\".4.\")]\n",
    "\n",
    "    # add a new \"determanind\" column containing the last part of the key\n",
    "    sensor_df[\"determinand\"] = sensor_df[\"key\"].str.split(\".\").str[-1]\n",
    "\n",
    "    # add a new \"tank\" column containing the first part of the key\n",
    "    sensor_df[\"tank\"] = sensor_df[\"key\"].str[:-3]\n",
    "\n",
    "    # add a new \"unit\" column containing the unit for the determinand\n",
    "    sensor_df[\"unit\"] = sensor_df[\"determinand\"].map(unit_mapping)\n",
    "\n",
    "    # drop the key column\n",
    "    sensor_df = sensor_df.drop(columns=[\"key\"])\n",
    "\n",
    "    # convert any values that are \"*\" to NaN\n",
    "    sensor_df[\"value\"] = sensor_df[\"value\"].replace(\"*\", np.nan)\n",
    "\n",
    "    # convert the value column to numeric\n",
    "    sensor_df[\"value\"] = pd.to_numeric(sensor_df[\"value\"], errors='raise')\n",
    "\n",
    "    # delete any temperature measurements between 14th an 19th july 2023 which are less than 0 degrees\n",
    "    sensor_df = sensor_df[~((sensor_df[\"timestamp\"] > \"2023-07-14\") & (sensor_df[\"timestamp\"] < \"2023-07-19\") & (sensor_df[\"determinand\"] == \"ts\") & (sensor_df[\"value\"] < 0))]\n",
    "\n",
    "    # Remove gc data where the tank is \"AMB\"\n",
    "    sensor_df = sensor_df[~((sensor_df[\"tank\"] == \"AMB\") & (sensor_df[\"determinand\"] == \"gc\"))]\n",
    "\n",
    "    return sensor_df\n",
    "\n",
    "sensor_df = clean_sensor_df(sensor_df)\n",
    "# sensor_df2 = clean_sensor_df(sensor_df2)\n",
    "\n",
    "# sensor_df2.to_csv('sensor_data_cleaned_august_onward.csv', index=False)\n",
    "sensor_df.to_csv('sensor_data_cleaned.csv', index=False)\n",
    "\n",
    "\n",
    "# merge the two dataframes\n",
    "# sensor_df = pd.concat([sensor_df2, sensor_df], axis=0, ignore_index=True)\n",
    "sensor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decimate the sensor data by 12 (optional)\n",
    "\n",
    "small_sensor_df = pd.DataFrame()\n",
    "for t in sensor_df[\"tank\"].unique():\n",
    "    for d in sensor_df[\"determinand\"].unique():\n",
    "\n",
    "        \n",
    "        # select the data for the current tank and determinand\n",
    "        df = sensor_df[(sensor_df[\"tank\"] == t) & (sensor_df[\"determinand\"] == d)]\n",
    "\n",
    "        # decimate the data by 12, by doing an average of the value column, while keeping the other columns\n",
    "        if d in [\"gc\"]: #don't do with gc data\n",
    "            decimation = 1\n",
    "        else:\n",
    "            decimation = 12\n",
    "        df = df.groupby(np.arange(len(df))//decimation).agg({'value':'mean', 'timestamp':'first', 'determinand':'first', 'tank':'first', 'unit':'first'})\n",
    "\n",
    "        # round the value column to 2 decimal places\n",
    "        df[\"value\"] = df[\"value\"].round(2)\n",
    "\n",
    "        # #add the decimated data back into the main dataframe\n",
    "        small_sensor_df = pd.concat([small_sensor_df, df], axis=0, ignore_index=True)\n",
    "\n",
    "small_sensor_df.to_csv('sensor_data_decimated_cleaned.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to combine and average the data from the 3 replicate tanks\n",
    "\n",
    "def combine_replicates(df_in, groupby=\"H\"):\n",
    "\n",
    "    df = df_in.copy()\n",
    "\n",
    "    avg_list = [\"INLET\", \"CON\", \"INS\", \"20C\", \"30C\", \"AMB\"]\n",
    "    # avg_list = [\"30C\"]\n",
    "\n",
    "    avg_df = pd.DataFrame()\n",
    "\n",
    "    for t in avg_list:\n",
    "\n",
    "        df = df_in.copy()\n",
    "        \n",
    "        # select data 3 replicate tanks\n",
    "        df = df[df[\"tank\"].str.startswith(t)]\n",
    "\n",
    "        # Convert 'timestamp' to datetime if it's not already\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True)\n",
    "\n",
    "        #convert to timezone naive timestamps IS THIS RIGHT?\n",
    "        df['timestamp'] = df['timestamp'].dt.tz_localize(None)\n",
    "\n",
    "        # split the 3 tanks into their own columns\n",
    "        df = df.pivot_table(index=['timestamp', 'determinand', 'unit'], columns='tank', values='value')\n",
    "\n",
    "        # add a new timestamp column\n",
    "        df[\"timestamp2\"] = df.index.get_level_values(0)\n",
    "\n",
    "        # Round 'timestamp' to the nearest hour\n",
    "        df['timestamp2'] = df['timestamp2'].dt.floor(groupby)\n",
    "\n",
    "\n",
    "        # average rows where the timestamps and determinands are the same\n",
    "        df = df.groupby(['timestamp2', 'determinand', 'unit']).mean()\n",
    "\n",
    "        # add an extra column for the average of the 3 tanks\n",
    "        df[\"value\"] = df.mean(axis=1)\n",
    "\n",
    "        # round the value column to 2 decimal places\n",
    "        df = df.round(2)\n",
    "\n",
    "        # remove the columns that start with t\n",
    "        df = df.drop(columns=[c for c in df.columns if c.startswith(t)])\n",
    "\n",
    "\n",
    "\n",
    "        # reset the index\n",
    "        df = df.reset_index()\n",
    "\n",
    "        # add a new column for the tank name\n",
    "        df[\"tank\"] = f\"{t}.AVG\"\n",
    "\n",
    "        # rename timestamp2 to timestamp\n",
    "        df = df.rename(columns={\"timestamp2\": \"timestamp\"})\n",
    "\n",
    "        debug1_df = df.copy()                     \n",
    "\n",
    "        # concat with avg_df\n",
    "        avg_df = pd.concat([avg_df, df], axis=0, ignore_index=True)\n",
    "    # return debug1_df\n",
    "    return avg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# for the ph determinand, apply smoothing to the data, this needs to be done on a tank by tank basis\n",
    "for t in sensor_df[\"tank\"].unique():\n",
    "    # select the ph data for the current tank\n",
    "    ph_df = sensor_df[(sensor_df[\"tank\"] == t) & (sensor_df[\"determinand\"] == \"ph\")]\n",
    "    smoothed_values = ph_df[\"value\"].rolling(3, center=True).mean().round(2)\n",
    "\n",
    "    # replace the original ph data with the smoothed data\n",
    "    sensor_df.loc[ph_df.index, \"value\"] = smoothed_values\n",
    "\n",
    "\n",
    "# Create a new \"lab_df\" from output_df, but with only the relevant columns\n",
    "lab_df = output_df[[\"timestamp\", \"value\", \"tank\", \"determinand\", \"unit\"]].copy()\n",
    "\n",
    "avg_sensor_df = combine_replicates(sensor_df)\n",
    "small_avg_sensor_df = combine_replicates(small_sensor_df)\n",
    "avg_lab_df = combine_replicates(lab_df, groupby=\"D\")\n",
    "\n",
    "# join the sensor_df and lab_df dataframes\n",
    "full_df = pd.concat([sensor_df, lab_df], axis=0, ignore_index=True)\n",
    "small_df = pd.concat([small_sensor_df, lab_df], axis=0, ignore_index=True)\n",
    "avg_df = pd.concat([avg_sensor_df, avg_lab_df], axis=0, ignore_index=True)\n",
    "small_avg_df = pd.concat([small_avg_sensor_df, avg_lab_df], axis=0, ignore_index=True)\n",
    "\n",
    "# sort the output dataframe by tank, and timestamp\n",
    "# the tank column needs to be in the order INLET, CON.1, CON.2, CON.3, INS.1, INS.2, INS.3, 20C.1, 20C.2, 20C.3, 30C.1, 30C.2, 30C.3\n",
    "\n",
    "full_order = {\n",
    "    \"INLET\": 0,\n",
    "    \"AMB\": 1, \n",
    "    \"CON.AVG\": 2,\n",
    "    \"CON.1\": 3,\n",
    "    \"CON.2\": 4,\n",
    "    \"CON.3\": 5,\n",
    "    \"INS.AVG\": 6,\n",
    "    \"INS.1\": 7,\n",
    "    \"INS.2\": 8,\n",
    "    \"INS.3\": 9,\n",
    "    \"20C.AVG\": 10,\n",
    "    \"20C.1\": 11,\n",
    "    \"20C.2\": 12,\n",
    "    \"20C.3\": 13,\n",
    "    \"30C.AVG\": 14,\n",
    "    \"30C.1\": 15,\n",
    "    \"30C.2\": 16,\n",
    "    \"30C.3\": 17,\n",
    "}\n",
    "\n",
    "avg_order = {\n",
    "    \"INLET\": 0,\n",
    "    \"CON.AVG\": 1,\n",
    "    \"INS.AVG\": 2,\n",
    "    \"20C.AVG\": 3,\n",
    "    \"30C.AVG\": 4,\n",
    "}\n",
    "\n",
    "# create a new column that is a number mapped from the tank name, in the order we want\n",
    "full_df[\"tank_num\"] = full_df[\"tank\"].map(full_order)\n",
    "small_df[\"tank_num\"] = small_df[\"tank\"].map(full_order)\n",
    "avg_df[\"tank_num\"] = avg_df[\"tank\"].map(avg_order)\n",
    "small_avg_df[\"tank_num\"] = small_avg_df[\"tank\"].map(avg_order)\n",
    "\n",
    "\n",
    "full_df.sort_values(by=[\"tank_num\", \"timestamp\"], inplace=True)\n",
    "small_df.sort_values(by=[\"tank_num\", \"timestamp\"], inplace=True)\n",
    "avg_df.sort_values(by=[\"tank_num\", \"timestamp\"], inplace=True)\n",
    "small_avg_df.sort_values(by=[\"tank_num\", \"timestamp\"], inplace=True)\n",
    "\n",
    "full_df.to_csv('full_df.csv', index=False)\n",
    "small_df.to_csv('small_df.csv', index=False)\n",
    "avg_df.to_csv('avg_df.csv', index=False)\n",
    "small_avg_df.to_csv('small_avg_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def export_to_excel_simple_pivot(df_in, sheet_name, timestamp_group=\"H\"):\n",
    "    df = df_in.copy()\n",
    "    output_data = pd.DataFrame()\n",
    "    # convert the timestamp column to datetime\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    # df = df[(df[\"timestamp\"] >= start_date) & (df[\"timestamp\"] <= end_date)]\n",
    "\n",
    "    # # remove the AMB data  \n",
    "    # df = df[~df[\"tank\"].str.contains(\"AMB\")]\n",
    "\n",
    "    # for each tank, keep only the ts data where the timestamp is closest to the gc data\n",
    "    for t in df[\"tank\"].unique():\n",
    "        tank_data = pd.DataFrame()\n",
    "\n",
    "        #Ambient data doesn't have a gc sensor, so we need to use the CON data\n",
    "        if t == \"AMB.AVG\":\n",
    "            gc_tank = \"CON.AVG\"\n",
    "        elif t == \"AMB\":\n",
    "            gc_tank = \"CON.1\"\n",
    "        else:\n",
    "            gc_tank = t\n",
    "\n",
    "        gc_data = df[df[\"tank\"] == gc_tank]\n",
    "        gc_data = gc_data[gc_data[\"determinand\"] == \"gc\"]\n",
    "        gc_data = gc_data.rename(columns={\"value\": \"gc\"})\n",
    "        gc_data = gc_data[[\"timestamp\", \"gc\"]]\n",
    "        gc_data = gc_data.sort_values(\"timestamp\")\n",
    "\n",
    "        other_data = df[df[\"tank\"] == t]\n",
    "        # filter for only the sensor determinands [\"ts, tl, pr, ph\"]\n",
    "        sensor_data = other_data[other_data[\"determinand\"].isin([\"ts\", \"tl\", \"pr\", \"ph\"])]\n",
    "        \n",
    "        for det in sensor_data[\"determinand\"].unique():\n",
    "            det_data = sensor_data.copy()\n",
    "            det_data = det_data[det_data[\"determinand\"] == det]\n",
    "            det_data = det_data.rename(columns={\"value\": f\"{det}\"})\n",
    "            det_data = det_data[[\"timestamp\", f\"{det}\"]]\n",
    "            det_data = det_data.sort_values(\"timestamp\")\n",
    "\n",
    "            merged_data = pd.merge_asof(gc_data, det_data, on=\"timestamp\", direction=\"nearest\")\n",
    "            merged_data[\"tank\"] = t\n",
    "\n",
    "            # add the merged data to an output dataframe\n",
    "            if tank_data.empty:\n",
    "                tank_data = merged_data\n",
    "            else:   \n",
    "                tank_data = pd.merge(tank_data, merged_data, how=\"outer\", on=[\"timestamp\", \"gc\", \"tank\"])\n",
    "\n",
    "        output_data = pd.concat([output_data, tank_data], axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "    # output data will be empty if just lab data is present\n",
    "    if not output_data.empty:\n",
    "        # condense the tl ts pr ph and gc data into a single column, with a determinand column to say which is which\n",
    "        output_data = output_data.melt(id_vars=[\"timestamp\", \"tank\"], value_vars=[\"gc\", \"tl\", \"ts\", \"pr\", \"ph\"], var_name=\"determinand\", value_name=\"value\")\n",
    "\n",
    "    #concat in the lab data\n",
    "    lab_data = df[~df[\"determinand\"].isin([\"ts\", \"tl\", \"pr\", \"ph\", \"gc\"])]\n",
    "    output_data = pd.concat([output_data, lab_data], axis=0, ignore_index=True)\n",
    "\n",
    "    #round down timestamp to nearest hour, and convert to string for excel\n",
    "    output_data[\"timestamp\"] = output_data[\"timestamp\"].dt.floor(timestamp_group)\n",
    "    output_data[\"timestamp\"] = output_data[\"timestamp\"].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    # pivot the data so that the determinands are in columns\n",
    "    pivot_data = output_data.pivot_table(index=['timestamp' ], columns=['determinand', 'tank'], values='value')\n",
    "\n",
    "    # Order the columns according to full_order, but with determinand at the top level\n",
    "    new_columns = pd.MultiIndex.from_product([pivot_data.columns.levels[0], full_order.keys()])\n",
    "    pivot_data = pivot_data.reindex(columns=new_columns)\n",
    "\n",
    "    # Drop any columns that are all NaN\n",
    "    pivot_data = pivot_data.dropna(axis=1, how='all')\n",
    "\n",
    "    # drop the amb gc column as it is not valid (actually contains con data)\n",
    "    # pivot_data = pivot_data.drop(columns=[(\"gc\", \"AMB\")])\n",
    "\n",
    "    # if an amb gc column exists, remove it\n",
    "    if (\"gc\", \"AMB\") in pivot_data.columns:\n",
    "        pivot_data = pivot_data.drop(columns=[(\"gc\", \"AMB\")])\n",
    "    if (\"gc\", \"AMB.AVG\") in pivot_data.columns:\n",
    "        pivot_data = pivot_data.drop(columns=[(\"gc\", \"AMB.AVG\")])   \n",
    "\n",
    "    # open excel workbok for appending\n",
    "    with pd.ExcelWriter(\"simple_data.xlsx\", engine='openpyxl', mode='a', if_sheet_exists=\"replace\") as writer:\n",
    "\n",
    "        # write the data to the excel file, replacing sheet if it exists\n",
    "        pivot_data.to_excel(writer, sheet_name=sheet_name)\n",
    "        output_data.to_excel(writer, sheet_name=sheet_name+\" for excel Pivot\")\n",
    "\n",
    "\n",
    "export_to_excel_simple_pivot(sensor_df, \"sensor data\")\n",
    "export_to_excel_simple_pivot(lab_df, \"lab data\", timestamp_group=\"D\")\n",
    "export_to_excel_simple_pivot(avg_sensor_df, \"avg data\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qc/j5fjcz915rzglws8xzct4cqh0000gn/T/ipykernel_37434/1348773959.py:8: FutureWarning:\n",
      "\n",
      "'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_data = df.copy()\n",
    "sheet_name = \"selected data\"\n",
    "timestamp_group = \"H\"\n",
    "\n",
    "#round down timestamp to nearest hour, and convert to string for excel\n",
    "# Ensure the 'timestamp' column is of datetime type\n",
    "output_data[\"timestamp\"] = pd.to_datetime(output_data[\"timestamp\"])\n",
    "output_data[\"timestamp\"] = output_data[\"timestamp\"].dt.floor(timestamp_group)\n",
    "output_data[\"timestamp\"] = output_data[\"timestamp\"].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# pivot the data so that the determinands are in columns\n",
    "pivot_data = output_data.pivot_table(index=['timestamp' ], columns=['determinand', 'tank'], values='value')\n",
    "\n",
    "# Order the columns according to full_order, but with determinand at the top level\n",
    "new_columns = pd.MultiIndex.from_product([pivot_data.columns.levels[0], full_order.keys()])\n",
    "pivot_data = pivot_data.reindex(columns=new_columns)\n",
    "\n",
    "# Drop any columns that are all NaN\n",
    "pivot_data = pivot_data.dropna(axis=1, how='all')\n",
    "\n",
    "# drop the amb gc column as it is not valid (actually contains con data)\n",
    "# pivot_data = pivot_data.drop(columns=[(\"gc\", \"AMB\")])\n",
    "\n",
    "# if an amb gc column exists, remove it\n",
    "if (\"gc\", \"AMB\") in pivot_data.columns:\n",
    "    pivot_data = pivot_data.drop(columns=[(\"gc\", \"AMB\")])\n",
    "if (\"gc\", \"AMB.AVG\") in pivot_data.columns:\n",
    "    pivot_data = pivot_data.drop(columns=[(\"gc\", \"AMB.AVG\")])   \n",
    "\n",
    "# open excel workbok for appending\n",
    "with pd.ExcelWriter(\"simple_data.xlsx\", engine='openpyxl', mode='a', if_sheet_exists=\"replace\") as writer:\n",
    "\n",
    "    # write the data to the excel file, replacing sheet if it exists\n",
    "    pivot_data.to_excel(writer, sheet_name=sheet_name)\n",
    "    output_data.to_excel(writer, sheet_name=sheet_name+\" for excel Pivot\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"2024-10-15\"\n",
    "end_date = \"2024-11-08\"\n",
    "\n",
    "df = sensor_df.copy()\n",
    "df = df[(df[\"timestamp\"] >= start_date) & (df[\"timestamp\"] <= end_date)]\n",
    "df = df[df[\"determinand\"].isin([\"ts\", \"tl\", \"gc\", \"ph\"])]\n",
    "df = df[df[\"tank\"].str.startswith(\"20\") | df[\"tank\"].str.startswith(\"30\")]\n",
    "# df = df[df[\"tank\"].str.startswith(\"CON\") | df[\"tank\"].str.startswith(\"INS\")]\n",
    "\n",
    "\n",
    "# remove the AMB data  \n",
    "df = df[~df[\"tank\"].str.contains(\"AMB\")]\n",
    "\n",
    "#\n",
    "\n",
    "# format the timestamp data for excel\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "df[\"timestamp\"] = df[\"timestamp\"].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# export the data to a xlsx file\n",
    "df.to_excel(\"selected_data.xlsx\", index=False)\n",
    "df.to_csv(\"selected_data.csv\", index=False)\n",
    "\n",
    "\n",
    "# plot selected data using plotly\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.line(df,\n",
    "                x=\"timestamp\",\n",
    "                y=\"value\",\n",
    "                color=\"tank\",\n",
    "                # line_group=\"determinand\",\n",
    "                # hover_name=\"determinand\",\n",
    "                title=\"CH4 Concentration (%)\",\n",
    "                facet_row=\"determinand\",)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"CH4 Concentration (%)\",\n",
    "    xaxis_title=\"Date\",\n",
    "    # yaxis_title=\"CH4 Concentration (%)\",\n",
    "    legend_title=\"Tank\",\n",
    ")\n",
    "\n",
    "fig.update_yaxes(matches=None)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"2023-06-01\"\n",
    "end_date = \"2023-09-20\"\n",
    "\n",
    "output_data = pd.DataFrame()\n",
    "\n",
    "df = sensor_df.copy()\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "df = df[(df[\"timestamp\"] >= start_date) & (df[\"timestamp\"] <= end_date)]\n",
    "\n",
    "# print type of timestamp column\n",
    "\n",
    "# # remove the AMB data  \n",
    "# df = df[~df[\"tank\"].str.contains(\"AMB\")]\n",
    "\n",
    "\n",
    "gc_data = df[df[\"determinand\"] == \"gc\"]\n",
    "\n",
    "# for each determinand, keep only the data where the timestamp is closest to the gc data\n",
    "for det in df[\"determinand\"].unique():\n",
    "\n",
    "    if det == \"gc\":\n",
    "        continue\n",
    "\n",
    "    det_data = df[df[\"determinand\"] == det]\n",
    "\n",
    "    for tank in det_data[\"tank\"].unique():\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "        merged_data = pd.merge_asof(gc_data, det_data, on=\"timestamp\", direction=\"nearest\")\n",
    "        merged_data[\"tank\"] = t\n",
    "\n",
    "        # add the merged data to an output dataframe\n",
    "        if tank_data.empty:\n",
    "            tank_data = merged_data\n",
    "        else:   \n",
    "            tank_data = pd.merge(tank_data, merged_data, how=\"outer\", on=[\"timestamp\", \"gc\", \"tank\"])\n",
    "\n",
    "    output_data = pd.concat([output_data, tank_data], axis=0, ignore_index=True)\n",
    "# output_data[\"timestamp\"] = output_data[\"timestamp\"].strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "output_data.to_csv('output_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"2023-08-25\"\n",
    "end_date = \"2023-09-25\"\n",
    "\n",
    "selected_data = sensor_df[(sensor_df[\"timestamp\"] >= start_date) & (sensor_df[\"timestamp\"] <= end_date)]\n",
    "selected_data = selected_data[selected_data[\"determinand\"].isin([\"ts\", \"tl\"])]\n",
    "\n",
    "# format the timestamp data for excel\n",
    "selected_data[\"timestamp\"] = pd.to_datetime(selected_data[\"timestamp\"])\n",
    "selected_data[\"timestamp\"] = selected_data[\"timestamp\"].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# export the data to a xlsx file\n",
    "selected_data.to_excel(\"selected_data.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
